{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great, now that we discussed a little let's continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the current approach utilized by the authors lacks reproducibility, we will explore an alternative method by leveraging nf-core pipelines for data analysis.\n",
    "\n",
    "Please explain, how we will achieve reproducibility for the course  with this approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using nf-core pipelines we can ensure that each persons analysis of the data uses the same steps with the same versions of the same tools with the same profiles and parameters, since all these properties of the analysis are controlled through nf-core. Although we still have to make sure that we write all of the parameters and pipelines and such down, so that others can see what we did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully downloaded 2 of the fastq files we will use in our study.\n",
    "\n",
    "What is the next step if we want to first have a count table and check the quality of our fastq files? What is the pipeline called to do so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is called rnaseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the 2 files using an nf-core pipeline.\n",
    "\n",
    "What does this pipeline do?\n",
    "\n",
    "Which are the main tools that will be used in the pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline runs an analysis on rna sequencing data to create an expression matrix of the genes of the organism. It also provides a report on the data.\n",
    "\n",
    "The pipeline starts with data preprocessing using tools such as salmon, UMI-tools, Trim Galore!, BBSplit and SortMeRNA to infer strandedness, extract unique molecular identifiers, trim, remove genome contaminants and ribosomal RNA to process the rna into a well usable form. Then follows a genome alignment and quantification using either STAR and Salmon, STAR and RSEM, or HiSAT2. Afterwards the data is post-processed, the report is compiled, and the quality is assessed. It is also possible to do a pseudo alignment using Salmon or Kallisto. The most important tools are probabliy STAR, Salmon, and RSEM, since they do the alignment and quantification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all other nf-core pipelines, the chosen pipeline takes in a samplesheet as input.\n",
    "\n",
    "Use Python and pandas to create the samplesheet for your 2 samples. Feel free to make use of the table you created earlier today.\n",
    "\n",
    "Choose your sample names wisely, they must be the connection of the results to the metadata. If you can't find the sample in the metadata later, the analysis was useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post here the command you used to run nf-core/rnaseq\n",
    "! nextflow run nf-core/rnaseq --input samplesheet.csv --outdir day2_output -profile singularity --genome GRCm38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain all the parameters you set and why you set them in this way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--input samplesheet.csv is the path to the samplesheet containing the names of the fastq files as well as supplementary data.\n",
    "\n",
    "--outdir day2_output is the parameter which specifies into which directory the output should be saved.\n",
    "\n",
    "-profile singularity specifies which tool is used for the containerization of the processes. Here I used singularity since it works better with codespaces and android.\n",
    "\n",
    "--genome GRCm38 is the reference genome against which the samples are mapped. In this case it uses the Mouse ID so the pipeline automatically downloads the reference genome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browsing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the pipeline perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the quality control steps. Are you happy with the quality and why. If not, why not.\n",
    "Please give additional information on : \n",
    "- ribosomal rRNA\n",
    "- Duplication\n",
    "- GC content\n",
    "\n",
    "What are the possible steps that could lead to poorer results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you exclude any samples? If yes, which and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you now do to continue the experiment? What are the scientists trying to figure out? Which packages on R or python would you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
