{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4 - Nextflow Basics: Introduction to channels and operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will begin exploring Nextflow, the programming language that powers the advanced nf-core pipelines you worked with last week. Your task is to dive into the core concepts and syntax of Nextflow, understanding how this language enables the development of scalable and reproducible workflows.\n",
    "\n",
    "Nextflow works quite differently from traditional programming languages like Python or Java that you may already be familiar with. To get started, it is essential to understand the foundational concepts that set Nextflow apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Describe the concept of Workflows, Processes and Channels we deal with in Nextflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflows:\n",
    "A workflow is a collection of sequential data analysis and processing steps that build on each other, using the previous steps output data as input for further steps.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Processes:\n",
    "A process is a discrete step in a workflow such as the application of a certain tool.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Channels:\n",
    "Channels are used to transfer data between processes. They are used to provide input data and receive output data. They function as one-directional queues for for files or other data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to channels\n",
    "\n",
    "Please refer to the file  $\\texttt{channels\\_intro.nf}$ for the next exercises. Then run the code with the respective flag here below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mfriendly_knuth\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mef2427ad57\u001b[m\n",
      "\u001b[K\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - Create a channel that enumerates the numbers from 1 to 10\n",
    "!nextflow run channels_intro.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mvoluminous_blackwell\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m1e8b2be1fa\u001b[m\n",
      "\u001b[K\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "k\n",
      "l\n",
      "m\n",
      "n\n",
      "o\n",
      "p\n",
      "q\n",
      "r\n",
      "s\n",
      "t\n",
      "u\n",
      "v\n",
      "w\n",
      "x\n",
      "y\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Create a channel that gives out the entire alphabet\n",
    "!nextflow run channels_intro.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36msad_hirsch\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m5713710cc8\u001b[m\n",
      "\u001b[K\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_4.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_3.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_1.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_5.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_2.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_1.fq\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - Create a channel that includes all files in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mecstatic_einstein\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m5d1ab3630a\u001b[m\n",
      "\u001b[K\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_4.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_3.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_1.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_5.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_2.txt\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - Create a channel that includes all TXT files in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mnostalgic_ride\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36me195512353\u001b[m\n",
      "\u001b[K\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq\n"
     ]
    }
   ],
   "source": [
    "# Task 5 - Create a channel that includes the files \"fastq_1.fq\" and \"fastq_2.fq\" in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mberserk_snyder\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m4035351615\u001b[m\n",
      "\u001b[K\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_4.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_3.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_1.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_5.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/.hidden_1.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_2.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_2.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/.hidden_2.txt\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_1.fq\n"
     ]
    }
   ],
   "source": [
    "# Task 6 - go back to the time when you included all files. Are you sure that really ALL files are included? If not, how can you include them?\n",
    "# The hidden files weren't collected, adding hidden: true as an option in the path fixes this\n",
    "!nextflow run channels_intro.nf --step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `channels_intro.nf` \u001b[0;2m[\u001b[0;1;36mhigh_mccarthy\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m5327209380\u001b[m\n",
      "\u001b[K\n",
      "[fastq3, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_2.fq]]\n",
      "[fastq5, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_2.fq]]\n",
      "[SRR3, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_2.fq]]\n",
      "[SRR1, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_2.fq]]\n",
      "[SRR4, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_2.fq]]\n",
      "[fastq4, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_2.fq]]\n",
      "[fastq1, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_2.fq]]\n",
      "[SRR5, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_2.fq]]\n",
      "[file, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_1.txt, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/file_2.txt]]\n",
      "[fastq2, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_2.fq]]\n",
      "[fastq, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq]]\n",
      "[.hidden, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/.hidden_1.txt, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/.hidden_2.txt]]\n",
      "[SRR2, [/workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_1.fq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_2.fq]]\n"
     ]
    }
   ],
   "source": [
    "# Task 7 - get all filepairs in the \"files_dir\" directory\n",
    "!nextflow run channels_intro.nf --step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that you have a solid understanding of the basic concepts of channels in Nextflow, it’s time to experiment and see how they work in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, Nextflow has the concept of Operators to give and pass information inbetween channels.\n",
    "\n",
    "Please answer the questions in $\\texttt{basic\\_channel\\_operations.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mcondescending_leibniz\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m3b5dcf40e8\u001b[m\n",
      "\u001b[K\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - Extract the first item from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mexotic_liskov\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36me9e5703fdf\u001b[m\n",
      "\u001b[K\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - Extract the last item from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mgolden_cajal\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m5ff4901160\u001b[m\n",
      "\u001b[K\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - Use an operator to extract the first two items from the channel\n",
    "!nextflow run basic_channel_operations.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36msleepy_hamilton\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mefb04f1f85\u001b[m\n",
      "\u001b[K\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - Return the squared values of the channel\n",
    "!nextflow run basic_channel_operations.nf --step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mmighty_rutherford\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mefb04f1f85\u001b[m\n",
      "\u001b[K\n",
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Task 5 - Remember the previous task where you squared the values of the channel. Now, extract the first two items from the squared channel\n",
    "!nextflow run basic_channel_operations.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mprickly_hugle\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mef46da3bdb\u001b[m\n",
      "\u001b[K\n",
      "rolyaT\n",
      "tfiwS\n"
     ]
    }
   ],
   "source": [
    "# Task 6 - Remember when you used bash to reverse the output? Try to use map and Groovy to reverse the output\n",
    "!nextflow run basic_channel_operations.nf --step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mdeadly_hodgkin\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36ma88a219b4e\u001b[m\n",
      "\u001b[K\n",
      "[fastq3_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_1.fq]\n",
      "[SRR5_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_2.fq]\n",
      "[fastq4_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_1.fq]\n",
      "[fastq, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq.fq]\n",
      "[fastq3_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq3_2.fq]\n",
      "[SRR3_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_1.fq]\n",
      "[fastq2_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_1.fq]\n",
      "[fastq5_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_2.fq]\n",
      "[SRR1_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_2.fq]\n",
      "[SRR, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR.fq]\n",
      "[fastq_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_2.fq]\n",
      "[SRR2_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_2.fq]\n",
      "[fastq1_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_2.fq]\n",
      "[fastq5_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq5_1.fq]\n",
      "[SRR3_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR3_2.fq]\n",
      "[SRR1_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR1_1.fq]\n",
      "[SRR4_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_1.fq]\n",
      "[SRR4_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR4_2.fq]\n",
      "[fastq4_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq4_2.fq]\n",
      "[fastq1_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq1_1.fq]\n",
      "[SRR5_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR5_1.fq]\n",
      "[fastq2_2, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq2_2.fq]\n",
      "[fastq_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/fastq_1.fq]\n",
      "[SRR2_1, /workspaces/computational-workflows-2025/notebooks/day_04/files_dir/SRR2_1.fq]\n"
     ]
    }
   ],
   "source": [
    "# Task 7 - Use fromPath to include all fastq files in the \"files_dir\" directory, then use map to return a pair containing the file name and the file path (Hint: include groovy code)\n",
    "!nextflow run basic_channel_operations.nf --step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mhigh_mcnulty\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mde77b7c555\u001b[m\n",
      "\u001b[K\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Task 8 - Combine the items from the two channels into a single channel\n",
    "!nextflow run basic_channel_operations.nf --step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mboring_lagrange\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36ma225f612dd\u001b[m\n",
      "\u001b[K\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Task 9 - Flatten the list in the channel\n",
    "!nextflow run basic_channel_operations.nf --step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mscruffy_pare\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m929d7bd8b3\u001b[m\n",
      "\u001b[K\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Task 10 - Collect the items of a channel into a list. What kind of channel is the output channel?\n",
    "!nextflow run basic_channel_operations.nf --step 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of channel is the output channel?\n",
    "\n",
    "The output channel is a single value channel containing a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mmarvelous_kay\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36ma89a6cd8fe\u001b[m\n",
      "\u001b[K\n",
      "[1, [V, f, B]]\n",
      "[3, [M, G, 33]]\n",
      "[2, [O, L, E]]\n"
     ]
    }
   ],
   "source": [
    "# Task 11 -  From the input channel, create lists where each first item in the list of lists is the first item in the output channel, followed by a list of all the items its paired with\n",
    "!nextflow run basic_channel_operations.nf --step 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mfestering_allen\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m86cc7dea0b\u001b[m\n",
      "\u001b[K\n",
      "[1, f, V]\n",
      "[3, G, M]\n",
      "[2, L, O]\n"
     ]
    }
   ],
   "source": [
    "# Task 12 - Create a channel that joins the input to the output channel. What do you notice?\n",
    "!nextflow run basic_channel_operations.nf --step 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 12 - What do you notice compared to Task 11?\n",
    "\n",
    "The \"33\" associated with the key 3 is missing. Additionally, join doesn't emit the key and its values as a tuple of key and list, it instead emits all of them in the same list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mgrave_cuvier\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m466f3b83d9\u001b[m\n",
      "\u001b[K\n",
      "Odd:  [1, 3, 5, 7, 9]\n",
      "Even: [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Task 13 - Split the input channel into two channels, one of all the even numbers and the other of all the odd numbers.\n",
    "#           Write them to stdout including information about which is which\n",
    "!nextflow run basic_channel_operations.nf --step 13 -dump-channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basic_channel_operations.nf` \u001b[0;2m[\u001b[0;1;36mpensive_brattain\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36md3100d8f71\u001b[m\n",
      "\u001b[K\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/results/names.txt\n",
      "Snape\n",
      "Albus\n",
      "Ron\n",
      "Hagrid\n",
      "Dobby\n",
      "Hermione\n",
      "Harry\n"
     ]
    }
   ],
   "source": [
    "# Task 14 - Nextflow has the concept of maps. Write the names in the maps in this channel to a file called \"names.txt\". Each name should be on a new line. \n",
    "#           Store the file in the \"results\" directory under the name \"names.txt\"\n",
    "\n",
    "!nextflow run basic_channel_operations.nf --step 14\n",
    "\n",
    "!cat results/names.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we learned about Channels and Operators to deal with them, let's focus on Processes that make use of these channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the questions in $\\texttt{basics\\_processes.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mclever_lamarck\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mb3e8a38b73\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34md8/53ddad\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO\u001b[2m |\u001b[m 0 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "HELLO WORLD!\u001b[K\n",
      "\u001b[K\n",
      "\u001b[5A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34md8/53ddad\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "HELLO WORLD!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - create a process that says Hello World! (add debug true to the process right after initializing to be sable to print the output to the console)\n",
    "!nextflow run basics_processes.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mdreamy_franklin\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m146441b28b\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m54/0d6f5d\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PYTHON\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m54/0d6f5d\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PYTHON\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "HELLO WORLD!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - create a process that says Hello World! using Python\n",
    "!nextflow run basics_processes.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36msmall_nightingale\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m1daed0713e\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PARAM\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m13/98bb39\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_PARAM\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "Hello world!\u001b[K\n",
      "\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 3 - create a process that reads in the string \"Hello world!\" from a channel and write it to command line\n",
    "!nextflow run basics_processes.nf --step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36msilly_laplace\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36m1bcd8cfa8f\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34md2/2eeee0\u001b[0;2m] \u001b[0;2m\u001b[mSAYHELLO_FILE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - create a process that reads in the string \"Hello world!\" from a channel and write it to a file. \n",
    "!nextflow run basics_processes.nf --step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be that you created the file but it doesnt appear in the directory. Use the work folder and the output on the command line to find the file.\n",
    "\n",
    "The file is located in Nextflows working directory under /work/d2/2eeee0aa8d582d99ecdcdbae14c325/greeting.txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 25.04.7\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `basics_processes.nf` \u001b[0;2m[\u001b[0;1;36mserene_wing\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mced8efe4e1\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE -\u001b[K\n",
      "\u001b[2A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m5a/3443d2\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/work/5a/3443d2c3613c09939e93181311348d/GREETING.txt\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m5a/3443d2\u001b[0;2m] \u001b[0;2m\u001b[mUPPERCASE\u001b[33;2m (\u001b[0;33m1\u001b[2m)\u001b[m\u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "/workspaces/computational-workflows-2025/notebooks/day_04/work/5a/3443d2c3613c09939e93181311348d/GREETING.txt\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 5 - create a process that reads in a string and converts it to uppercase and saves it to a file as output. View the path to the file in the console\n",
    "!nextflow run basics_processes.nf --step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6 - add another process that reads in the resulting file from UPPERCASE and print the content to the console (debug true).\n",
    "!nextflow run basics_processes.nf --step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comared to all the other runs. What changed in the output here and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7 - based on the paramater \"zip\" (see at the head of the file), create a process that zips the file created in the UPPERCASE process either in \"zip\", \"gzip\" OR \"bzip2\" format.\n",
    "#          Print out the path to the zipped file in the console\n",
    "!nextflow run basics_processes.nf --step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8 - Create a process that zips the file created in the UPPERCASE process in \"zip\", \"gzip\" AND \"bzip2\" format. Print out the paths to the zipped files in the console\n",
    "!nextflow run basics_processes.nf --step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Task 9 - Create a process that reads in a list of names and titles from a channel and writes them to a file.\n",
    "#           Store the file in the \"results\" directory under the name \"names.tsv\"\n",
    "!nextflow run basics_processes.nf --step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"results/names.tsv\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's try some more advanced Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the questions in $\\texttt{advanced\\_channel\\_operations.nf}$ and run the code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To come closer to actual pipelines, we introduce the concept of \"meta-maps\" which you can imagine as dictionaries that are passed with data via channels containing crucial metadata on the sample. \n",
    "\n",
    "Also, we will come back to samplesheets which you should remember from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Read in the samplesheet.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Read in the samplesheet and create a meta-map with all metadata and another list with the filenames ([[metadata_1 : metadata_1, ...], [fastq_1, fastq_2]]).\n",
    "#          Set the output to a new channel \"in_ch\" and view the channel. YOU WILL NEED TO COPY AND PASTE THIS CODE INTO SOME OF THE FOLLOWING TASKS (sorry for that).\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 - Now we assume that we want to handle different \"strandedness\" values differently. \n",
    "#          Split the channel into the right amount of channels and write them all to stdout so that we can understand which is which.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 3 -dump-channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 - Group together all files with the same sample-id and strandedness value.\n",
    "\n",
    "!nextflow run advanced_channel_operations.nf --step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's finally time to link processes and channels with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please go to the file $\\texttt{link\\_p\\_c.nf}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nextflow run link_p_c.nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give a list with the paths to the chunk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why was CONVERTTOUPPER run so often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
